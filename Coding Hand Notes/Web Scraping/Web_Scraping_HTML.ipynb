{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping and Extracting Data using REST APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTML structure\n",
    "Hypertext markup language (HTML) serves as the foundation of web pages. Understanding its structure is crucial for web scraping.<br>\n",
    "\n",
    "* `<html>` is the root element of an HTML page.<br>\n",
    "* `<head>` contains meta-information about the HTML page.<br>\n",
    "* `<body>` displays the content on the web page, often the data of interest.<br>\n",
    "* `<h3>` tags are type 3 headings, making text larger and bold, typically used for player names.<br>\n",
    "* `<p>` tags represent paragraphs and contain player salary information.<br>\n",
    "\n",
    "\n",
    "### Composition of an HTML tag\n",
    "HTML tags define the structure of web content and can contain attributes.<br>\n",
    "\n",
    "* An HTML tag consists of an opening (start) tag and a closing (end) tag.<br>\n",
    "* Tags have names (`<a>` for an anchor tag).<br>\n",
    "* Tags may contain attributes with an attribute name and value, providing additional information to the tag.<br>\n",
    "\n",
    "\n",
    "### HTML document tree\n",
    "You can visualize HTML documents as trees with tags as nodes.<br>\n",
    "\n",
    "* Tags can contain strings and other tags, making them the tag's children.<br>\n",
    "* Tags within the same parent tag are considered siblings.<br>\n",
    "* For example, the `<html>` tag contains both `<head>` and `<body>` tags, making them descendants of `<html>` but children of `<html>`. `<head>` and `<body>` are siblings.<br>\n",
    "\n",
    "&emsp;&emsp;<img src=\"../Pictures/DOM_structure.png\"/>\n",
    "\n",
    "\n",
    "### HTML tables\n",
    "HTML tables are essential for presenting structured data.<br>\n",
    "\n",
    "* Define an HTML table using the `<table>` tag.<br>\n",
    "* Each table row is defined with a `<tr>` tag.<br>\n",
    "* The first row often uses the table header tag, typically `<th>`.<br>\n",
    "* The table cell is represented by `<td>` tags, defining individual cells in a row.<br>\n",
    "\n",
    "\n",
    "&emsp;&emsp;<img src=\"../Pictures/HTML Tables.png\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uniform resource locator (URL)\n",
    "\n",
    "Uniform resource locator (URL) is the most popular way to find resources on the web.  We can break the URL into three parts.\n",
    "\n",
    "<ul>\n",
    "    <li><b>Scheme</b>:- This is this protocol, for this lab it will always be <code>http://</code>  </li>\n",
    "    <li><b> Internet address or  Base URL </b>:- This will be used to find the location here are some examples: <code>www.ibm.com</code> and  <code> www.gitlab.com </code> </li>\n",
    "    <li><b>Route</b>:- Location on the web server for example: <code>/images/IDSNlogo.png</code> </li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTTP Methods\n",
    "\n",
    "<ul>\n",
    "    <li><b>Get</b> retrieves data from the server </li>\n",
    "    <li><b>Post</b> submits data to server </li>\n",
    "    <li><b>Put</b> updates data already on server </li>\n",
    "    <li><b>Delete</b> deletes data from server </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages\n",
    "`BeautifulSoup` library for interpreting the `HTML` document. Beautiful represents HTML as a set of Tree like objects with methods used to parse the HTML<br>\n",
    "\n",
    "`requests` library to communicate with the web page. It allows you to send <code>HTTP/1.1</code> requests easily.<br>\n",
    "\n",
    "`sqlite3` for creating the database instance<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "# Requests Library Demo\n",
    "\n",
    "import requests\n",
    "import os\n",
    "# from PIL import Image\n",
    "# from IPython.display import IFrame\n",
    "\n",
    "url='https://www.ibm.com/'\n",
    "r=requests.get(url)\n",
    "print(r.status_code)\n",
    "print(r.status_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting beautifulsoup4\n",
      "  Downloading beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4)\n",
      "  Downloading soupsieve-2.5-py3-none-any.whl.metadata (4.7 kB)\n",
      "Downloading beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.9/147.9 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading soupsieve-2.5-py3-none-any.whl (36 kB)\n",
      "Installing collected packages: soupsieve, beautifulsoup4\n",
      "Successfully installed beautifulsoup4-4.12.3 soupsieve-2.5\n",
      "Collecting requests\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests)\n",
      "  Downloading charset_normalizer-3.3.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (33 kB)\n",
      "Collecting idna<4,>=2.5 (from requests)\n",
      "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests)\n",
      "  Downloading urllib3-2.2.1-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests) (2024.6.2)\n",
      "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading charset_normalizer-3.3.2-cp312-cp312-macosx_11_0_arm64.whl (119 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.1/121.1 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: urllib3, idna, charset-normalizer, requests\n",
      "Successfully installed charset-normalizer-3.3.2 idna-3.7 requests-2.32.3 urllib3-2.2.1\n",
      "appnope==0.1.4\n",
      "asttokens==2.4.1\n",
      "beautifulsoup4==4.12.3\n",
      "certifi==2024.6.2\n",
      "charset-normalizer==3.3.2\n",
      "comm==0.2.2\n",
      "debugpy==1.8.1\n",
      "decorator==5.1.1\n",
      "distlib==0.3.8\n",
      "executing==2.0.1\n",
      "filelock==3.14.0\n",
      "idna==3.7\n",
      "ipykernel==6.29.4\n",
      "ipython==8.25.0\n",
      "jedi==0.19.1\n",
      "jupyter_client==8.6.2\n",
      "jupyter_core==5.7.2\n",
      "matplotlib-inline==0.1.7\n",
      "nest-asyncio==1.6.0\n",
      "numpy==1.26.4\n",
      "packaging==24.0\n",
      "pandas==2.2.2\n",
      "parso==0.8.4\n",
      "pexpect==4.9.0\n",
      "pipenv==2023.12.1\n",
      "platformdirs==4.2.2\n",
      "prompt_toolkit==3.0.45\n",
      "psutil==5.9.8\n",
      "ptyprocess==0.7.0\n",
      "pure-eval==0.2.2\n",
      "Pygments==2.18.0\n",
      "python-dateutil==2.9.0.post0\n",
      "pytz==2024.1\n",
      "pyzmq==26.0.3\n",
      "requests==2.32.3\n",
      "setuptools==70.0.0\n",
      "six==1.16.0\n",
      "soupsieve==2.5\n",
      "stack-data==0.6.3\n",
      "tornado==6.4\n",
      "traitlets==5.14.3\n",
      "tzdata==2024.1\n",
      "urllib3==2.2.1\n",
      "virtualenv==20.26.2\n",
      "wcwidth==0.2.13\n"
     ]
    }
   ],
   "source": [
    "# Installing packages\n",
    "!pip3 install beautifulsoup4\n",
    "!pip3 install requests\n",
    "# Check all installed packages and version\n",
    "!pip3 freeze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab Scenario\n",
    "Consider that you have been hired by a Multiplex management organization to extract the information of the top 50 movies with the best average rating from the web link shared below.<br>\n",
    "https://web.archive.org/web/20230902185655/https://en.everybodywiki.com/100_Most_Highly-Ranked_Films<br>\n",
    "\n",
    "The information required is `Average Rank`, `Film`, and `Year`.<br><br>\n",
    "You are required to write a Python script `webscraping_movies.py` that extracts the information and saves it to a `CSV` file `top_50_films.csv`. You are also required to save the same information to a database `Movies.db` under the table name `Top_50`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# webscraping_movies.py\n",
    "\n",
    "import requests\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import os \n",
    "\n",
    "url = 'https://web.archive.org/web/20230902185655/https://en.everybodywiki.com/100_Most_Highly-Ranked_Films'\n",
    "db_name = 'Movies.db'\n",
    "table_name = 'Top_50'\n",
    "csv_path = os.path.join(os.getcwd(),'top_50_films.csv')\n",
    "df = pd.DataFrame(columns=[\"Average Rank\",\"Film\",\"Year\"])\n",
    "count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the webpage for Webscrapping\n",
    "html_page = requests.get(url).text\n",
    "data = BeautifulSoup(html_page, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = data.find_all('tbody')\n",
    "rows = tables[0].find_all('tr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Average Rank                                           Film  Year\n",
      "0             1                                  The Godfather  1972\n",
      "1             2                                   Citizen Kane  1941\n",
      "2             3                                     Casablanca  1942\n",
      "3             4                         The Godfather, Part II  1974\n",
      "4             5                            Singin' in the Rain  1952\n",
      "5             6                                         Psycho  1960\n",
      "6             7                                    Rear Window  1954\n",
      "7             8                                 Apocalypse Now  1979\n",
      "8             9                          2001: A Space Odyssey  1968\n",
      "9            10                                  Seven Samurai  1954\n",
      "10           11                                        Vertigo  1958\n",
      "11           12                                    Sunset Blvd  1950\n",
      "12           13                                   Modern Times  1936\n",
      "13           14                             Lawrence of Arabia  1962\n",
      "14           15                             North by Northwest  1959\n",
      "15           16                                      Star Wars  1977\n",
      "16           17                                       Parasite  2019\n",
      "17           18                               Schindler's List  1993\n",
      "18           19  Lord of the Rings: The Fellowship of the Ring  2001\n",
      "19           20                           Shawshank Redemption  1994\n",
      "20           21                          It's a Wonderful Life  1946\n",
      "21           22                                   Pulp Fiction  1994\n",
      "22           23                              Avengers: Endgame  2019\n",
      "23           24                                    City Lights  1931\n",
      "24           25                One Flew Over the Cuckoo's Nest  1975\n",
      "25           26                                     Goodfellas  1990\n",
      "26           27                        Raiders of the Lost Ark  1981\n",
      "27           28                                   12 Angry Men  1957\n",
      "28           29                       The Silence of the Lambs  1991\n",
      "29           30                                    Taxi Driver  1976\n",
      "30           31                            Saving Private Ryan  1998\n",
      "31           32                     E.T. the Extra Terrestrial  1982\n",
      "32           33                                          Alien  1979\n",
      "33           34              Spider-Man: Into the Spider-verse  2018\n",
      "34           35                                   Blade Runner  1982\n",
      "35           36                               Double Indemnity  1944\n",
      "36           37                                The Dark Knight  2008\n",
      "37           38                               The Wizard of Oz  1939\n",
      "38           39  Star Wars: Episode V- The Empire Strikes Back  1980\n",
      "39           40                                  The Searchers  1956\n",
      "40           41                             Mad Max: Fury Road  2015\n",
      "41           42                                      Inception  2010\n",
      "42           43          Lord of the Rings: Return of the King  2003\n",
      "43           44                                     The Matrix  1999\n",
      "44           45                                     Fight Club  1999\n",
      "45           46                             Back to the Future  1985\n",
      "46           47                          It Happened One Night  1934\n",
      "47           48                The Good, the Bad, and the Ugly  1966\n",
      "48           49              Lord of the Rings: The Two Towers  2002\n",
      "49           50                                  All About Eve  1950\n"
     ]
    }
   ],
   "source": [
    "for row in rows:\n",
    "    if count<50:\n",
    "        col = row.find_all('td')\n",
    "        if len(col)!=0:\n",
    "            data_dict = {\"Average Rank\": col[0].contents[0],\n",
    "                         \"Film\": col[1].contents[0],\n",
    "                         \"Year\": col[2].contents[0]}\n",
    "            df1 = pd.DataFrame(data_dict, index=[0])\n",
    "            df = pd.concat([df,df1], ignore_index=True)\n",
    "            count+=1\n",
    "    else:\n",
    "        break\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(csv_path)\n",
    "\n",
    "conn = sqlite3.connect(db_name)\n",
    "df.to_sql(table_name, conn, if_exists='replace', index=False)\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MONTHLYREPORT-omFkZ47_",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
